{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(500, 431, 3)\n",
      "dets:  rectangles[[(117, 118) (340, 341)]]\n",
      "INFO:tensorflow:Restoring parameters from train_models/age_gender_tensornets_wiki_cropface_model_20180525_180944\n",
      "age:  11\n",
      "gender:  [0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b3c79e96320c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mgender_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"male\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mgender\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"female\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgender_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m#print(\"age: \" + str(age[i]) + \"gender: \" + str(gender[i]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import age_gender_test\n",
    "from age_gender_model import * \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "img_path = \"./images/56_female.jpg\"\n",
    "model_path = \"./train_models/age_gender_tensornets_wiki_cropface_model_20180525_180944\"\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "    \n",
    "detector = dlib.get_frontal_face_detector() #获取人脸分类器\n",
    "\n",
    "def add_margin(img, face_loc):\n",
    "    crop_h = int(0.4 * (face_loc[3] - face_loc[1]))\n",
    "    crop_w = int(0.4 * (face_loc[2] - face_loc[0]))\n",
    "    img_h = img.shape[0]\n",
    "    img_w = img.shape[1]\n",
    "    #new_crop_low = crop_h + face_loc[1] - crop_h\n",
    "    new_crop_high = crop_h + face_loc[3] + crop_h\n",
    "    #new_crop_left = crop_w + face_loc[0] - crop_w\n",
    "    new_crop_right = crop_w + face_loc[2] + crop_w\n",
    "    replicate = cv2.copyMakeBorder(img, crop_h, crop_h, crop_w, crop_w, cv2.BORDER_REPLICATE)\n",
    "    crop_face_img = replicate[face_loc[1] : new_crop_high, face_loc[0] : new_crop_right]\n",
    "    return crop_face_img\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    print(img.shape)\n",
    "    #b, g, r = cv2.split(img)    # 分离三个颜色通道\n",
    "    #img = cv2.merge([r, g, b])   # 融合三个颜色通道生成新图片\n",
    "    \n",
    "    dets = detector(img, 1) #使用detector进行人脸检测 dets为返回的结果\n",
    "    \n",
    "    #input_tensor = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    HH, WW, _ = img.shape\n",
    "    faces_data = np.zeros([len(dets), 224, 224, 3])\n",
    "    print(\"dets: \", dets)\n",
    "    for index, face in enumerate(dets):        \n",
    "        # 在图片中标注人脸，并显示\n",
    "        left = face.left()\n",
    "        top = face.top()\n",
    "        right = face.right()\n",
    "        bottom = face.bottom()\n",
    "        w = right - left\n",
    "        h = bottom - top\n",
    "        left = int(max(0, left - 0.4 * w))\n",
    "        top = int(max(0, top - 0.4 * h))\n",
    "        right = int(min(WW, right + 0.4 * w))\n",
    "        bottom = int(min(HH, bottom + 0.4 * h))\n",
    "\n",
    "        face_img = img[top:bottom, left:right].copy()\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "        face_img = cv2.resize(face_img, (224, 224))\n",
    "        cv2.imshow(\"?!!!!\", face_img)\n",
    "        faces_data[index] = face_img\n",
    "        \n",
    "        \"\"\"        face_loc = np.array([162.616728383582,97.9220370301495,307.299783928807,242.605092575374])\n",
    "                face_loc = (face_loc).astype(\"int32\")\n",
    "                face_img = add_margin(img, face_loc)\n",
    "                face_img = cv2.resize(face_img, (224, 224))\n",
    "                faces_data[index] = face_img\"\"\"\n",
    "    #print(\"faces_data.shape\", faces_data.shape)\n",
    "    age, gender = run_test_temp(sess, faces_data, model_path)\n",
    "    print(\"age: \", age)\n",
    "    print(\"gender: \", gender)\n",
    "    for i in range(len(dets)):\n",
    "        #cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        if top - 20 < 0:\n",
    "            top = top + 25\n",
    "        else:\n",
    "            top = top - 10\n",
    "        gender_text = \"male\" if gender[i] == 1 else \"female\"\n",
    "        cv2.putText(img,str(int(age[i])) + \", \" + gender_text,(left,top), font, 1,(0,255,0),1,cv2.LINE_AA)\n",
    "        cv2.imshow(\"test\", img)\n",
    "        #print(\"age: \" + str(age[i]) + \"gender: \" + str(gender[i]))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(268, 400, 3)\n",
      "255\n",
      "0\n",
      "(321600,)\n",
      "104\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 10040] 一个在数据报套接字上发送的消息大于内部消息缓冲区或其他一些网络限制，或该用户用于接收数据报的缓冲区比数据报小。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-14e48e16e613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#print(msg[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mlength_send\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength_send\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10040] 一个在数据报套接字上发送的消息大于内部消息缓冲区或其他一些网络限制，或该用户用于接收数据报的缓冲区比数据报小。"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "img_path = \"./images/28_female.jpg\"\n",
    "model_path = \"./train_models/age_gender_tensornets_wiki_cropface_model_20180523_123604\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector() #获取人脸分类器\n",
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "address = ('35.227.146.91', 60000)  \n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  \n",
    "\n",
    "print(np.max(img))\n",
    "print(np.min(img))\n",
    "img = img.reshape([-1])\n",
    "print(img.shape)\n",
    "print(img[13])\n",
    "msg = bytearray(img.shape[0])\n",
    "for i in range(img.shape[0]):\n",
    "    #t = int(img[i])\n",
    "    #print(i)\n",
    "    #p = t.to_bytes(1, 'big')\n",
    "    msg[i] = img[i]\n",
    "    #print(msg[i])\n",
    "length_send = s.sendto(msg, address)\n",
    "print(length_send)\n",
    "s.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "address = ('127.0.0.1', 31500)  \n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  \n",
    "s.bind(address)  \n",
    "\n",
    "while True:  \n",
    "    data, addr = s.recvfrom(2048)  \n",
    "    if not data:  \n",
    "        print(\"client has exist\")\n",
    "        break  \n",
    "    print(\"received:\", data, \"from\", addr)\n",
    "  \n",
    "s.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
